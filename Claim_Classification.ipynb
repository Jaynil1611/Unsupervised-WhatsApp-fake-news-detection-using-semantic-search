{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Claim_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "94Wz9Ey0BpO_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9c05aae7-d61e-4c12-c34b-6bb4d9043750"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtsFyanqBzHv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7016d5ec-122e-437d-c594-77a83690d2b0"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "%cd /content/drive/My Drive/Colab Notebooks/Probabilistic-RNN-DA-Classifier\n",
        "import datetime\n",
        "import time\n",
        "from keras.models import load_model\n",
        "from utilities import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Probabilistic-RNN-DA-Classifier\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P57AWGecB_EN"
      },
      "source": [
        "resource_dir = 'data/'\n",
        "embeddings_dir = \"embeddings/\"\n",
        "model_dir = 'models/'\n",
        "model_name = 'Probabilistic Model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIceR9ZlCBoQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "77bc7c28-a44e-40ac-923e-539fcb569cee"
      },
      "source": [
        "# Load metadata\n",
        "metadata = load_data(resource_dir + \"metadata.pkl\")\n",
        "word_frequency = 2\n",
        "frequency_data = load_data(embeddings_dir + 'probabilistic_freq_' + str(word_frequency) + '.pkl')\n",
        "\n",
        "# Load Training and test sets\n",
        "train_data = load_data(resource_dir + 'train_data.pkl')\n",
        "train_x, train_y = generate_probabilistic_embeddings(train_data, frequency_data, metadata)\n",
        "\n",
        "test_data = load_data(resource_dir + 'test_data.pkl')\n",
        "test_x, test_y = generate_probabilistic_embeddings(test_data, frequency_data, metadata)\n",
        "\n",
        "val_data = load_data(resource_dir + 'val_data.pkl')\n",
        "val_x, val_y = generate_probabilistic_embeddings(val_data, frequency_data, metadata)\n",
        "\n",
        "# Parameters\n",
        "vocabulary_size = metadata['vocabulary_size']\n",
        "num_labels = metadata['num_labels']\n",
        "max_utterance_len = metadata['max_utterance_len']\n",
        "batch_size = 100\n",
        "hidden_layer = 128\n",
        "learning_rate = 0.001\n",
        "num_epoch = 10\n",
        "model_name = model_name + \" -\" + \\\n",
        "             \" Epochs=\" + str(num_epoch) + \\\n",
        "             \" Hidden Layers=\" + str(hidden_layer)\n",
        "\n",
        "print(\"------------------------------------\")\n",
        "print(\"Using parameters...\")\n",
        "print(\"Vocabulary size: \", vocabulary_size)\n",
        "print(\"Number of labels: \", num_labels)\n",
        "print(\"Word frequency: \", word_frequency)\n",
        "print(\"Batch size: \", batch_size)\n",
        "print(\"Hidden layer size: \", hidden_layer)\n",
        "print(\"learning rate: \", learning_rate)\n",
        "print(\"Epochs: \", num_epoch)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded data from file data/metadata.pkl.\n",
            "Loaded data from file embeddings/probabilistic_freq_2.pkl.\n",
            "Loaded data from file data/train_data.pkl.\n",
            "Loaded data from file data/test_data.pkl.\n",
            "Loaded data from file data/val_data.pkl.\n",
            "------------------------------------\n",
            "Using parameters...\n",
            "Vocabulary size:  23103\n",
            "Number of labels:  41\n",
            "Word frequency:  2\n",
            "Batch size:  100\n",
            "Hidden layer size:  128\n",
            "learning rate:  0.001\n",
            "Epochs:  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9k_2klcCG47"
      },
      "source": [
        "def listToString(s):  \n",
        "    \n",
        "    # initialize an empty string \n",
        "    str1 = \"\"  \n",
        "    \n",
        "    # traverse in the string   \n",
        "    for ele in s:  \n",
        "        str1 += ele +\"\\n\"   \n",
        "    \n",
        "    # return string   \n",
        "    return str1  \n",
        "\n",
        "def gen_test(string):\n",
        "    lines=string.split('\\n');\n",
        "    res={'utterances':[],'labels':[]}\n",
        "    for line in lines:\n",
        "        res['utterances'].append(line.split(' '))\n",
        "        res['labels'].append('%')\n",
        "    return  generate_probabilistic_embeddings(res, frequency_data, metadata)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CED9Q5KBCI9R"
      },
      "source": [
        "model_dir = 'models/'\n",
        "model_name = 'Probabilistic Model'\n",
        "\n",
        "model_claim = load_model('/content/drive/My Drive/Colab Notebooks/Probabilistic-RNN-DA-Classifier/models/Probabilistic Model - Epochs=10 Hidden Layers=128.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziROwSvgCLOH"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/o.csv')\n",
        "df.drop('Unnamed: 0',inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSLjQ6IKDrig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ff21aec7-cd8d-4512-a311-3b8d10381a2d"
      },
      "source": [
        "d = list(df.Decrypted_Raw_Message.str.strip())\n",
        "s = listToString(d)\n",
        "s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Toh guys kya karna he\\n@917506854640 tu kal nai he toh aaj research kar konse topic pe karna he hume\\nEspecially GAN\\nWhy this new group?\\nKeep one only\\nSudhanshu aur wo be wala he na\\nToh isme\\nBaat kar sakte he\\nHalbe Ka mail id kya hai?\\nGive respect\\nFirst share with us for problem statement\\nThis message was deleted\\naparna_halbe@spit.ac\\nAre dataset bataya Nahi hai usko\\nHalbe mam bil\\nOk sir\\nSearch for research statement\\nBhai kal karna he ki nai?\\nGenomics â€“ Genomics is the study of DNA of organisms. Machine Learning systems can help in finding the location of protein-encoding genes in a DNA structure. Gene prediction is performed by using two types of searches named as extrinsic and intrinsic. Machine Learning is used in problems related to DNA alignment.\\nSearch for thee\\nTu ispe search karke ye group pe links daal @917303477011\\n@917506854640 tu tuje jo topic pasand he uspe kar and send\\nMe mera marta hu fir topic decide krte he\\n<Media omitted>\\nGuys aaj final karo\\nhttps://www.linkedin.com/posts/digitalis-kapha-b-v-_caeli-climatechange-ai-activity-6625707297471508480-35cx\\n#MP2\\nYou'll decide , I am out today\\nBhai aaj karna chalu karo toh kal mail kar denge\\nRply once read\\nAck\\nSearch for papers\\nSearch for News-Generator model already existing\\nOkayy\\nYep\\nSend papers\\nYou'll have sear\\nsearched\\nHaan\\nIn sometime\\nTuje mile wo send kar\\nAur kal tak likhna he bhai toh hi check hoga monday ko\\nHa\\nAre suno\\nWed abl me sir ne bola tha\\nJis conference me paper daalo ge udhar jo current topic chal raha he uspe karo\\nHave mailed\\nhttps://10times.com/india/technology/conferences\\nhttps://www.pantechsolutions.net/blog/artificial-intelligence-ai-projects/\\nhttps://towardsdatascience.com/generating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2\\nThis is awesome\\nWhat will we do\\nWe will stick to our idea\\n.\\nI meant ye code diya he\\nNo it is transfer learning in NLP\\nO\\nYes , I am talking about implementation\\nAlternative to GAN\\nToh will we stick to news article only?\\nYes\\n@917506854640 rply\\nThis guy has got logic in th text generated that's exactly what we want\\nHaa par\\nAre bhai aaj karo ?\\nYes\\nhttps://towardsdatascience.com/how-i-used-natural-language-processing-to-extract-context-from-news-headlines-df2cf5181ca6\\nhttps://medium.com/@ageitgey/deepfaking-the-news-with-nlp-and-transformer-models-5e057ebd697d\\nhttps://blog.parse.ly/post/7790/machine-learning-nlp-parse-ly-currents/\\nKal 9 am sharp colg pahoch jana dono 9-11 me khatam kar denge\\n<Media omitted>\\nðŸ˜‚ðŸ˜‚ðŸ‘ŒðŸ»ðŸ¤¦ðŸ»â€â™‚\\nSubmit kal karenge\\nK\\nSearch for reference papers\\nAre humlog upload kar dete he\\nAyushi ka group kar raha he\\nK\\nTry to search about\\r\\n What's farzo\\nWhat's farzi \\r\\n Detection techniques\\nHaa\\n11% kisme aya @917303477011\\nNo\\nNp\\nI have done it\\nHaaðŸ‘ðŸ»\\nSee the new resuly\\nresults\\nYess barabar he\\nIt is similar to Turnitin\\n& effective tool\\nHaa acha he\\nhttps://www.duplichecker.com/\\nNow I am sending to Aparna mam\\nHaa\\nKab karna he feasibility studyCv\\n?*\\n@917506854640 @917303477011\\nTuesday\\nAcha\\nGuys try to do scraping of web.whats app .com\\nYash we will do Feasibility study tomorrow evening\\nOkayy\\nAaj karna he ki kal subah?\\nAaj\\nOk\\n6 pm\\nOk\\nTell Jaswant about our project\\nKya bolu\\nSend abstract document\\nTo him\\nAre usko already bola\\nNene\\nMene\\nK\\nI have shared the document\\nComing\\nhttps://www.kaggle.com/c/fake-news/overview\\n@918169471348\\nYe us k news ka he\\nFir whatsapp ka dataset bhi US ka chahiye\\nIt is for only training purpose only\\nAfter training we will apply what's app data\\nScan all the notebooks and analyse the common  algorithm\\nWhich uses Neutral Networks and whose Accuracy is high\\nAlso Opinion vs Classifier is inpr\\nImportant\\nAchaa\\nGuys we need to complete our model by 15/16 March so that agar kidhar reject hua toh aur kidhar bhej sakte he\\nAtleast basic model ban jaye\\nRHS maâ€™am ne bola he ki last time jo humne diet ka app ka  bhara tha na government k liye wo shayad select hoga abhi\\nToh wo banana he\\nLet's see\\nGuys we will complete architectural diagrams tomorrow morning\\n@917506854640 please send the completed code for web scraping web.whatsapp.com which you have implemented\\nYash tell me which diagrams are to be done\\nSequence class architecure\\nI have sent the links\\nI have not got the link\\nAre toh tu banake bhejde na\\nWhat is the update Shubham\\nDekh message aur groups mill rahe hai\\nFormatting aur automation baaki hai\\nK, keep the code and data extracted in a presentable format\\nMake CSV file of data.\\nThat's formatting\\nWhich I will do tomorrow\\nYeah\\nSorry yaar time Nahi mil rha tha\\nPush the code on repository\\nWhich?\\nWe will also do the updatation required\\nScraping notebook\\nNo problem \\r\\n When is your internship getting over ?\\nBefore mse\\nThat's great\\nNo more internship work after that\\nData kis format me Chahiye bata\\nYeah\\n<Media omitted>\\nThis is the format.\\nCool\\nMP me complete Karna try karta hu\\nK\\nWhat's the update on this\\nBola nai\\nAsk\\nLeave it\\nShubham\\nAre maam saamne se bolegi jab result ayegi\\nSend the code of Web scraping\\nYash complete class diagram and sequence diagram\\nK\\nKal lab me kar dunga wo toh\\nKar diya\\n@917506854640  scrapping kiya ki nai?\\nSent\\nKal dikha denge toh\\nK\\nAlgo daal de bas\\nNahi\\nI will add flowchart\\nOkay\\n@917506854640 \\r\\n Scrap the exported chat of sender and receiver\\nDue to the increasing threat of coronavirus , it may be possible that the conference for which we are applying may get cancelled.\\r\\n So keep backup conferences ready before hand and pray that this virus is contained until next month.ðŸ™\\nWe might have to even change the conference\\nYeah keep backup conferences ready\\nHaan\\nSee the mail for abl\\n27 ko he\\nYeah\\nhttps://www.clarityinsights.com/blog/using-nlp-and-ai-to-detect-fake-news-with-99-accuracy\\nhttps://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\\nhttps://nycdatascience.com/blog/student-works/identifying-fake-news-nlp/\\nrefer the above websites to get clear idea what we are going to do\\n@917506854640 What is the update for dataset?\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATTnVchsCOqX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "e600bd9e-87ed-4792-b5ac-aaef11aa1925"
      },
      "source": [
        "p = model_claim.predict(gen_test(s)[0])\n",
        "claim_classified = {}\n",
        "try :\n",
        "    for i in range(len(p)):\n",
        "        # print(d[i],end=\" \")\n",
        "        # print(type(metadata['labels'][np.where(p[i] == np.amax(p[i]))[0][0]][0]))\n",
        "        if(metadata['labels'][np.where(p[i] == np.amax(p[i]))[0][0]][0]==\"sd\" or metadata['labels'][np.where(p[i] == np.amax(p[i]))[0][0]][0]==\"sv\"):\n",
        "            claim_classified[d[i]] = metadata['labels'][np.where(p[i] == np.amax(p[i]))[0][0]][0]\n",
        "except Exception as e:\n",
        "        print(e)\n",
        "keys = claim_classified.keys()\n",
        "for i in keys:\n",
        "  try:\n",
        "    if(len(i.split(\" \"))<=15):\n",
        "      claim_classified[i] = None\n",
        "  except Exception as e:\n",
        "    print(end=\"\")\n",
        "  if(claim_classified[i]!=None):\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list index out of range\n",
            "Genomics â€“ Genomics is the study of DNA of organisms. Machine Learning systems can help in finding the location of protein-encoding genes in a DNA structure. Gene prediction is performed by using two types of searches named as extrinsic and intrinsic. Machine Learning is used in problems related to DNA alignment.\n",
            "RHS maâ€™am ne bola he ki last time jo humne diet ka app ka  bhara tha na government k liye wo shayad select hoga abhi\n",
            "Due to the increasing threat of coronavirus , it may be possible that the conference for which we are applying may get cancelled.\r\n",
            " So keep backup conferences ready before hand and pray that this virus is contained until next month.ðŸ™\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJFeBi4zC474"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}